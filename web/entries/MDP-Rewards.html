<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Markov Decision Processes with Rewards - Archive of Formal Proofs
</title>
<link rel="stylesheet" type="text/css" href="../front.css">
<link rel="icon" href="../images/favicon.ico" type="image/icon">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<!-- MathJax for LaTeX support in abstracts -->
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  processEscapes: true,
  svg: {
    fontCache: 'global'
  }
};
</script>
<script id="MathJax-script" async src="../components/mathjax/es5/tex-mml-chtml.js"></script>
</head>

<body class="mathjax_ignore">

<table width="100%">
<tbody>
<tr>

<!-- Navigation -->
<td width="20%" align="center" valign="top">
  <p>&nbsp;</p>
  <a href="https://www.isa-afp.org/">
    <img src="../images/isabelle.png" width="100" height="88" border=0>
  </a>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
  <table class="nav" width="80%">
    <tr>
      <td class="nav" width="100%"><a href="../index.html">Home</a></td>
    </tr>
    <tr>
      <td class="nav"><a href="../about.html">About</a></td>
    </tr>
    <tr>
      <td class="nav"><a href="../submitting.html">Submission</a></td>
    </tr>
    <tr>
      <td class="nav"><a href="../updating.html">Updating Entries</a></td>
    </tr>
    <tr>
      <td class="nav"><a href="../using.html">Using Entries</a></td>
    </tr>
    <tr>
      <td class="nav"><a href="../search.html">Search</a></td>
    </tr>
    <tr>
      <td class="nav"><a href="../statistics.html">Statistics</a></td>
    </tr>
    <tr>
      <td class="nav"><a href="../topics.html">Index</a></td>
    </tr>
    <tr>
      <td class="nav"><a href="../download.html">Download</a></td>
    </tr>
  </table>
  <p>&nbsp;</p>
  <p>&nbsp;</p>
</td>


<!-- Content -->
<td width="80%" valign="top">
<div align="center">
  <p>&nbsp;</p>
  <h1>          <font class="first">M</font>arkov
  
          <font class="first">D</font>ecision
  
          <font class="first">P</font>rocesses
  
          with
  
          <font class="first">R</font>ewards
  
</h1>
  <p>&nbsp;</p>

<table width="80%" class="data">
<tbody>
<tr>
  <td class="datahead" width="20%">Title:</td>
  <td class="data" width="80%">Markov Decision Processes with Rewards</td>
</tr>

<tr>
  <td class="datahead">
          Authors:
      </td>
  <td class="data">
                    Maximilian Schäffeler (schaeffm /at/ in /dot/ tum /dot/ de) and
          <a href="http://home.in.tum.de/~mansour/">Mohammad Abdulaziz</a>
      </td>
</tr>



<tr>
  <td class="datahead">Submission date:</td>
  <td class="data">2021-12-16</td>
</tr>

<tr>
  <td class="datahead" valign="top">Abstract:</td>
  <td class="abstract mathjax_process">
We present a formalization of Markov Decision Processes with rewards.
In particular we first build on Hölzl's formalization  of MDPs
(AFP entry: Markov_Models) and extend them with rewards. We proceed
with an analysis of the expected total discounted reward criterion for
infinite horizon MDPs. The central result is the construction of the
iteration rule for the Bellman operator. We prove the optimality
equations for this operator and show the existence of an optimal
stationary deterministic solution. The analysis can be used to obtain
dynamic programming algorithms such as value iteration and policy
iteration to solve MDPs with formal guarantees. Our formalization is
based on chapters 5 and 6 in Puterman's book "Markov
Decision Processes: Discrete Stochastic Dynamic Programming".</td>
</tr>


<tr>
  <td class="datahead" valign="top">BibTeX:</td>
  <td class="formatted">
        <pre>@article{MDP-Rewards-AFP,
  author  = {Maximilian Schäffeler and Mohammad Abdulaziz},
  title   = {Markov Decision Processes with Rewards},
  journal = {Archive of Formal Proofs},
  month   = dec,
  year    = 2021,
  note    = {\url{https://isa-afp.org/entries/MDP-Rewards.html},
            Formal proof development},
  ISSN    = {2150-914x},
}</pre>
  </td>
</tr>

    <tr><td class="datahead">License:</td>
        <td class="data"><a href="http://isa-afp.org/LICENSE">BSD License</a></td></tr>

    
                    
                      <tr><td class="datahead">Used by:</td>
          <td class="data"><a href="MDP-Algorithms.html">MDP-Algorithms</a>      </td></tr>
          

        
  </tbody>
</table>

<p></p>

<table class="links">
  <tbody>
    <tr>
    <td class="links">
      <a href="../browser_info/current/AFP/MDP-Rewards/outline.pdf">Proof outline</a><br>
      <a href="../browser_info/current/AFP/MDP-Rewards/document.pdf">Proof document</a>
    </td>
    </tr>
    <tr>
    <td class="links">
      <a href="../browser_info/current/AFP/MDP-Rewards/index.html">Browse theories</a>
      </td></tr>
    <tr>
    <td class="links">
      <a href="../release/afp-MDP-Rewards-current.tar.gz">Download this entry</a>
    </td>
    </tr>


          <tr><td class="links">Older releases:
            None
            </td></tr>
    
  </tbody>
</table>

</div>
</td>

</tr>
</tbody>
</table>

<script src="../jquery.min.js"></script>
<script src="../script.js"></script>

</body>
</html>